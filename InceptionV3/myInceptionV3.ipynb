{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"myInceptionV3.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"aYn6B9log9xw","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BjavCgbs51px","colab_type":"code","outputId":"ad98d984-1f22-4cff-f91d-99ffaaad4f28","executionInfo":{"status":"ok","timestamp":1574721720191,"user_tz":480,"elapsed":1656,"user":{"displayName":"CYN DWITH","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCbu1q0NGDKUfvNWZNL5TWex3OHbt2g06xmbEZW=s64","userId":"15818765708014108245"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%tensorflow_version 2.x"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3tbTI7SFhNMN","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow_datasets as tfds\n","\n","# Tensorflow 2.0 has eager execution by default\n","# tf.compat.v1.enable_eager_execution()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hT0VLWp0hS2n","colab_type":"code","colab":{}},"source":["SPLIT_WEIGHTS = (8, 1, 1)\n","splits = tfds.Split.TRAIN.subsplit(weighted=SPLIT_WEIGHTS)\n","\n","(raw_train, raw_validation, raw_test), metadata = tfds.load(\n","    'cifar100', split=list(splits),\n","    with_info=True, as_supervised=True)\n","\n","print(metadata)\n","print(raw_train)\n","print(raw_validation)\n","print(raw_test)\n","\n","get_label_name = metadata.features['label'].int2str\n","print(get_label_name)\n","for image, label in raw_train.take(2):\n","  plt.figure()\n","  plt.imshow(image)\n","  plt.title(get_label_name(label))\n","\n","# Format the Data\n","IMG_SIZE = 346 # All images will be resized to 160x160\n","\n","def format_example(image, label):\n","  image = tf.cast(image, tf.float32)\n","  image = (image/255) \n","  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n","  return image, label\n","\n","# Apply this function to each item in the dataset using the map method:\n","cifar_train      = raw_train.map(format_example)\n","cifar_validation = raw_validation.map(format_example)\n","cifar_test       = raw_test.map(format_example)\n","\n","# Now shuffle and batch the data.\n","BATCH_SIZE = 32\n","SHUFFLE_BUFFER_SIZE = 1000\n","\n","cifar_train_batches      = cifar_train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n","cifar_validation_batches = cifar_validation.batch(BATCH_SIZE)\n","cifar_test_batches       = cifar_test.batch(BATCH_SIZE)\n","\n","for image_batch, label_batch in cifar_train_batches.take(1):\n","   pass\n","\n","image_batch.shape\n","\n","IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n","\n","# Create the base model from the pre-trained model Inception V3\n","base_model = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE,\n","                                               include_top=False,\n","                                               weights='imagenet')\n","\n","feature_batch = base_model(image_batch)\n","print(feature_batch.shape)\n","\n","# freeze convolution base\n","base_model.trainable = False\n","\n","base_model.summary()\n","\n","# Add classification / fine tune part\n","global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n","feature_batch_average = global_average_layer(feature_batch)\n","print(feature_batch_average.shape)\n","\n","prediction_layer = tf.keras.layers.Dense(100, activation='softmax')\n","prediction_batch = prediction_layer(feature_batch_average)\n","print(prediction_batch.shape)\n","\n","# stack the base model (feature extraction), classification\n","model = tf.keras.Sequential([\n","  base_model,\n","  global_average_layer,\n","  prediction_layer\n","])\n","\n","# compile the model\n","base_learning_rate = 0.0001\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.summary()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNrk9mgghky-","colab_type":"code","colab":{}},"source":["# Train the model\n","num_train, num_val, num_test = (\n","  metadata.splits['train'].num_examples*weight/10\n","  for weight in SPLIT_WEIGHTS\n",")\n","\n","initial_epochs = 10\n","steps_per_epoch = round(num_train)//BATCH_SIZE\n","validation_steps = 20\n","\n","loss0,accuracy0 = model.evaluate(cifar_validation_batches, steps = validation_steps)\n","\n","print(\"initial loss: {:.2f}\".format(loss0))\n","print(\"initial accuracy: {:.2f}\".format(accuracy0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r96-Nt44hpCx","colab_type":"code","colab":{}},"source":["history = model.fit(cifar_train_batches,\n","                    epochs=initial_epochs,\n","                    validation_data=cifar_validation_batches)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8RTShOAhrrt","colab_type":"code","colab":{}},"source":["# Learning curves\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([min(plt.ylim()),1])\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([0,1.0])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QEpuGaEhvCC","colab_type":"code","colab":{}},"source":["# Un freeze base model\n","base_model.trainable = True\n","\n","# Let's take a look to see how many layers are in the base model\n","print(\"Number of layers in the base model: \", len(base_model.layers))\n","\n","# Fine tune from this layer onwards\n","fine_tune_at = 100\n","\n","# Freeze all the layers before the `fine_tune_at` layer\n","for layer in base_model.layers[:fine_tune_at]:\n","  layer.trainable =  False\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.summary()\n","\n","len(model.trainable_variables)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0lZFhyjJOfYc","colab_type":"code","colab":{}},"source":["fine_tune_epochs = 10\n","total_epochs =  initial_epochs + fine_tune_epochs\n","history_fine = model.fit(cifar_train_batches,\n","                         epochs=total_epochs,\n","                         initial_epoch =  history.epoch[-1],\n","                         validation_data=cifar_validation_batches)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-249H6mOrKq","colab_type":"code","colab":{}},"source":["# append to the learning graph\n","acc += history_fine.history['accuracy']\n","val_acc += history_fine.history['val_accuracy']\n","\n","loss += history_fine.history['loss']\n","val_loss += history_fine.history['val_loss']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eYLPp3HjOygN","colab_type":"code","colab":{}},"source":["# plot the learning graphs\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.ylim([0, 1])\n","plt.plot([initial_epochs-1,initial_epochs-1],\n","          plt.ylim(), label='Start Fine Tuning')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","#plt.ylim([0, 10.0])\n","plt.plot([initial_epochs-1,initial_epochs-1],\n","         plt.ylim(), label='Start Fine Tuning')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qt8dhtZJO00-","colab_type":"code","colab":{}},"source":["# Evaluate the model\n","test_steps = 20\n","test_loss, test_accuracy = model.evaluate(cifar_test_batches, steps = test_steps)\n","\n","print(\"Test loss: {:.2f}\".format(test_loss))\n","print(\"Test accuracy: {:.2f}\".format(test_accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gISpldMjO2wo","colab_type":"code","colab":{}},"source":["# Convert Keras model to TF Lite format.\n","print(tf.__version__)\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_float_model = converter.convert()\n","\n","# Show model size in KBs.\n","float_model_size = len(tflite_float_model) / 1024\n","print('Float model size = %dKBs.' % float_model_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mdbtE8wO5ji","colab_type":"code","colab":{}},"source":["# Re-convert the model to TF Lite using quantization.\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_quantized_model = converter.convert()\n","\n","# Show model size in KBs.\n","quantized_model_size = len(tflite_quantized_model) / 1024\n","print('Quantized model size = %dKBs,' % quantized_model_size)\n","print('which is about %d%% of the float model size.'\\\n","      % (quantized_model_size * 100 / float_model_size))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ObKF7sYHPAC-","colab_type":"code","colab":{}},"source":["# Evaluate tensorflow lite model\n","cifar100 = tf.keras.datasets.cifar100\n","(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n","\n","# try just 100 images to save time\n","test_images = test_images[:100]\n","test_labesl = test_labels[:100]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jt7lhgR2PCzQ","colab_type":"code","colab":{}},"source":["def pre_process(image):\n","  image = tf.cast(image, tf.float32)\n","  image = (image/255)\n","  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n","  return image\n","\n","# A helper function to evaluate the TF Lite model using \"test\" dataset.\n","def evaluate_tflite_model(tflite_model):\n","  # Initialize TFLite interpreter using the model.\n","  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n","  interpreter.allocate_tensors()\n","  input_tensor_index = interpreter.get_input_details()[0][\"index\"]\n","  output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n","\n","  # Run predictions on every image in the \"test\" dataset.\n","  prediction_digits = []\n","  for test_image in test_images:\n","    # Pre-processing: add batch dimension and convert to float32 to match with\n","    # the model's input data format.\n","    test_image = pre_process(test_image)\n","    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n","    #print(test_image)\n","    #print(test_label)\n","    # test_image = test_image.astype(np.float32)\n","    interpreter.set_tensor(input_tensor_index, test_image)\n","    # Run inference.\n","    interpreter.invoke()\n","    # Post-processing: remove batch dimension and find the digit with highest\n","    # probability.\n","    digit = np.argmax(output()[0])\n","    # print(digit)\n","    prediction_digits.append(digit)\n","    # print(prediction_digits)\n","    # break\n","\n","  #prediction_digits = np.array(prediction_digits)\n","  #test_label = np.array(test_label)\n","  # Compare prediction results with ground truth labels to calculate accuracy.\n","  accurate_count = 0\n","  #print('prediction_digits:', len(prediction_digits))\n","  #print(prediction_digits)\n","  #print('test_label:', test_label)\n","  for index in range(len(prediction_digits)):\n","    #print('pred:', prediction_digits[index])\n","    #print('label shape:', test_labels.shape)\n","    #print('label:', test_labels[index])\n","    if prediction_digits[index] == test_labels[index]:\n","      accurate_count += 1\n","  accuracy = accurate_count * 1.0 / len(prediction_digits) \n","\n","  return accuracy\n","\n","# Evaluate the TF Lite float model. You'll find that its accurary is identical\n","# to the original TF (Keras) model because they are essentially the same model\n","# stored in different format.\n","float_accuracy = evaluate_tflite_model(tflite_float_model)\n","print('Float model accuracy = %.4f' % float_accuracy)\n","\n","# Evalualte the TF Lite quantized model.\n","# Don't be surprised if you see quantized model accuracy is higher than\n","# the original float model. It happens sometimes :)\n","quantized_accuracy = evaluate_tflite_model(tflite_quantized_model)\n","print('Quantized model accuracy = %.4f' % quantized_accuracy)\n","print('Accuracy drop = %.4f' % (float_accuracy - quantized_accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8CFbc-koPE8J","colab_type":"code","colab":{}},"source":["# Save the float model to file to the Downloads directory\n","f = open('/content/drive/My Drive/DeepGC/InceptionV3/myInceptionV3_float.tflite', \"wb\")\n","f.write(tflite_float_model)\n","f.close()\n","\n","# Save the quantized model to file to the Downloads directory\n","f = open('/content/drive/My Drive/DeepGC/InceptionV3/myInceptionV3_quant.tflite', \"wb\")\n","f.write(tflite_quantized_model)\n","f.close()\n","\n","# Download the cifar classification model\n","# from google.colab import files\n","# files.download('/content/drive/My Drive/DeepGC/MobileNetV2/myMobileNetV2.tflite')\n","# print('`myMobileNetV2` has been downloaded')"],"execution_count":0,"outputs":[]}]}